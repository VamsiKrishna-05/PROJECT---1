{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c21d838-7f46-4ad9-93cb-698263b4b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3055934-83ed-4024-b326-befbe00c5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths (Train and Test main folders)\n",
    "train_dir = r\"C:\\Users\\rpaka\\OneDrive\\Desktop\\dataset\\train\"\n",
    "test_dir  = r\"C:\\Users\\rpaka\\OneDrive\\Desktop\\dataset\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d37509b7-bca3-4be4-9fe2-649e66d8a367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode=\"categorical\"   # multi-class classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58611c2d-5280-49f2-82f1-21d792b1f2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load testing dataset\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8a2cca5-5529-4d7d-b649-f538357d17f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['non_violent', 'violent']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(\"Classes found:\",class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aca147a0-f147-46ac-ad01-b1ab8441d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x, y:(x/255.0,y))\n",
    "test_ds = test_ds.map(lambda x, y:(x/255.0,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "974d8f5f-c4a8-439f-a835-4395717e5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(len(class_names), activation='softmax')  # 4 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60b2fec8-0cd8-4195-9888-e78897557a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5842c55a-04f9-4550-956d-080c9d6fe43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6480 - loss: 0.6596 - val_accuracy: 0.7000 - val_loss: 0.3312\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.8560 - loss: 0.3038 - val_accuracy: 1.0000 - val_loss: 0.0473\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0280 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9920 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 1.8220e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9920 - loss: 0.0157 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9920 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 2.1746e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.8615e-04 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9920 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 2.1621e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 2.2631e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.4857e-04 - val_accuracy: 1.0000 - val_loss: 3.3402e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=test_ds,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63247b47-3bb1-49b1-ac9e-42c004e78e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# Iterate over the test dataset\n",
    "for images, labels in test_ds:\n",
    "    preds = model(images, training=False)  # safer than model.predict\n",
    "    preds = tf.argmax(preds, axis=1).numpy()      # convert to numpy array\n",
    "    true_labels = tf.argmax(labels, axis=1).numpy()\n",
    "    \n",
    "    y_pred.extend(preds)\n",
    "    y_true.extend(true_labels)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ca71d8c-4a70-4fbd-9e86-d2658c370f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[28  0]\n",
      " [ 0 12]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6aab04-ae46-410e-889f-8b2c50fe5f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717030d-a17f-4bb7-9076-ca8314694ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
